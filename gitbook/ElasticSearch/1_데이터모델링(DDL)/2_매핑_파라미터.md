# 참고자료

- [엘라스틱 서치 실무가이드](http://www.yes24.com/Product/Goods/71893929?OzSrank=1)

# 매핑 파라미터

모든 내용들을 다루기에는 조금 문서가 길어지지 않을까 싶다. 여기서는 주요하게 사용되는 파라미터들만을 정리해놓으려 한다. 바로 [이전 문서](https://gosgjung.gitbook.io/lognomy/lognomy/elastic-cloud/undefined/index-mapping-overview)에 살펴본 예제에서는 아래의 인덱스 매핑(DDL) 구문을 통해 인덱스의 생성과 동시에 타입매핑을 해주었었다.

```bash
PUT financial_yearly 
{
  "mappings":{
    "properties":{
      "stockCode": {
        "type": "keyword"
      },
      "stockName": {
        "type": "text",
        "analyzer": "standard"
      },
      "fundamental": {
        "properties": {
          "baseDate": {
            "type": "date",
            "format": "yyyy-MM-dd'T'HH:mm:ss||yyyy-MM-dd||epoch_millis||yyyyMMdd"
          },
          "pbr":{
            "type": "double"
          },
          "per":{
            "type": "double"
          }
        }
      }
    }
  }
}
```

stockName 필드를 자세히 보자. 아래와 같이 정의했었다. stockName 에 대해서 object 형식으로 데이터를 정의하는데 "type" 외에 "analyzer" 라는 항목이 하나 보인다. 그리고 analyzer 는 "standard" 라는 값을 갖는 하나의 키/값 쌍이다.

```bash
PUT financial_yearly 
{
  "mappings":{
    // ...
      "stockName": {
        "type": "text",
        "analyzer": "standard"
      },
    // ...
    }
  }
}
```

이 analyzer 라는 항목은 엘라스틱 서치에서 "**매핑 파라미터**" 라는 용어로 부른다. 기억해두자. 이런 `매핑 파라미터` 의 종류들을 종류별로 필요한 것만 요점만 간단히 정리해볼 생각이다. 깊이 있는 내용은 책에서 찾아보도록 하자.  

# analyzer

> text 타입의 필드는 analyzer 매핑 파라미터를 사용해야 하며, 누락했을 경우 해당 필드는 "standard" 분석기(analyzer)로 세팅된다.  

analyzer 가 적용되거나, 명시된 필드는  해당 필드가 형태소 분석의 대상이 된다. 색인(insert), 검색시 매핑시 지정한 분석기(analyzer)로 형태소 분석이 이뤄진다. 분석기(analyzer)의 종류는 여러가지가 있는데 위에서는 "standard" 를 지정했다. 

# normalizer

> 예를 들어 keyword 타입의 필드에 사용할 수 있는 형태소 분석기(analyzer)는 normalizer 이다. keyword 타입의 필드에 대해 standard 타입의 분석기(analyzer)를 사용할  경우 에러를 낸다. ([참고 - keyword 타입에 대해 standard analyzer 를 사용하려 할 때 에러가 나는 이유 - discuss.elastic.co](https://discuss.elastic.co/t/mapping-definition-for-fields-has-unsupported-parameters-analyzer-not-standard/204782))

매핑 파라미터 `normalizer` 는 term query 에 분석기를 사용하기 위해 사용된다. 예를 들어 keyword 타입의 필드를 형태소분석하려고 할 경우 'Kospi', 'KOSPI', kOSpi' 는 모두 다른 문자로 인식된다. 매핑시 매핑 파라미터로 normalizer 를 asciifolding 으로 지정하면 'Kospi', 'KOSPI', 'kOSpi' 는 같은 문자열로 인식될 수 있게 된다.  

ex)

```bash
PUT financial_yearly 
{
  "mappings":{
    // ...
      "stockCode": {
        "type": "keyword",
        "normalizer": "asciifolding"
      },
    // ...
    }
  }
}
```



# boost

최신 버전의 엘라스틱 서치는 색인시 boost 설정을 할 수 없도록 바뀌었다. 내부적으로 사용하는 루씬에서 기능이 제거되어서 라고 한다. ( [참고](https://stackoverflow.com/questions/45822066/index-time-field-level-boosting-in-lucene-6-6-0) )

# coerce

색인(INSERT) 시 자동 변환을 허용할지 여부를 설정하는 파라미터이다. 위에서 생성한 매핑 구문을 예로 들어보자

```bash
PUT financial_yearly 
{
  "mappings":{
    "properties":{
      "stockCode": {
        "type": "keyword"
      },
      "stockName": {
        "type": "text",
        "analyzer": "standard"
      },
      "fundamental": {
        "properties": {
          "baseDate": {
            "type": "date",
            "format": "yyyy-MM-dd'T'HH:mm:ss||yyyy-MM-dd||epoch_millis||yyyyMMdd"
          },
          "pbr":{
            "type": "double"
          },
          "per":{
            "type": "double"
          }
        }
      }
    }
  }
}
```

`fundamental.pbr` 필드의 경우 `double` 타입으로 지정되어 있다. 이 필드에 "100.00" 데이터가 들어왔을 때 coerce 옵션을 지정한 인덱스라면 "100.00" 을 100.00 으로 자동으로 형변환하여 저장해준다.  

# copy_to

생략.

# fielddata

> fielddata 는 엘라스틱서치가 힙 공간에 생성하는 **메모리 캐시**다. 메모리 부족 및 잦은 GC 관련 이슈로 인해 현재는 거의 사용되지 않고, text 타입의 필드에 대해서 정말 필요한 경우에 한해 사용하는 편이다. 최신 엘라스틱 서치 버전에서는 **doc_values** 라는 캐시를 사용한다. 

text 타입의 필드느 기본적으로 분석기에 의해 형태소 분석이 이루어진다. 따라서 집계나 정렬 등의 기능을 수행할 수 없다. 하지만 간혹 text 타입의 필드에 대해 집계, 정렬을 수행하는 경우 역시 존재할 수 있다. 이런 경우에 한해 fielddata 를 사용할 수 있다.(하지만, fielddata 는 메모리에 생성되는 캐시이기 때문에 최소한으로 사용해야 한다.)

사용 예제)

```bash
PUT financial_yearly 
{
  "mappings":{
    // ...
      "stockName": {
        "type": "text",
        "fielddata": true,
        "normalizer": "asciifolding"
      },
    // ...
    }
  }
}
```

# doc_values

엘라스틱 서치에서 사용하는 기본 캐시이다. text 타입 외의 거의 모든 타입에서 `doc_values` 캐시를 사용한다. `doc_values` 는 루씬 베이스의 캐시 방식이다. 정렬/집계가 필요없는 필드의 경우 `doc_values` 옵션을 비활성화하는 것이 권장된다. (한번 비활성화된 필드는 인덱스를 재색인 하지 않는 한 변경이 불가능하다.)  ‌

구조적으로는 OS 의 파일시스템의 캐시를 통해 디스크 내의 데이터에 빠르게 접근한다. 과거에는 캐시를 모두 메모리에 올려서 사용했는데, 위에서 살펴봤듯이 GC, 힙 메모리 부족 현상등을 야기했다고 한다. 현재는 `doc_values` 를 사용함으로써 메모리 부담을 줄였다. (버전이 올라가면서, 앞으로 또 어떻게 변할지는 살펴봐야 할 일인것 같다는 생각이 든다. 6.x 버전에 존재하는 type 개념을 없앤것만 보더라도, 언젠가는 없애는 개념들이 있지 않을까? 하는 두려움이 조금은 든다...)  

# format

시간/날짜를 매핑할 때 format 파라미터를 사용한다. 이 format 타입에 대해서는 아래의 링크를 확인하자. (나중에 정리할...예정이다 😅)

[Elasticsearch Reference [7.10] > Mapping > Mapping parameters > format](https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html)

# index

매핑 파라미터 `index`  는 필드 값을 색인할 지를 결정한다. 인덱스 매핑시 파라미터로 명시적으로 지정하지 않으면 자동으로 true 로 세팅된다. 매핑시 명시적으로 false로 세팅하면 필드를 색인하지 않게 된다.  

# fields‌

나도 이게 지금은 뭔지 잘 모르겠지만, 나중에 필요할 것 같아서 정리해놓는다. `fields` 옵션은 필드 안에 또 다른 필드의 정보를 추가할 수 잇기 때문에 같은 `fields` 로 선언한 필드는 전혀 다른 필드로 취급하여 분석기가 처리하게끔 할 수 있다.  

# norms (normalize, 정규화)

document(문서)의 `_score` 값 계산에 필요한 정규화 인수를 사용할지 여부를 결정한다. 아무 값도 지정하지 않고 매핑했을 때 묵시적으로 norms 파라미터는 true 로 지정된다. `_score` 계산이 필요없거나 단순 필터링 용도로 사용할 경우는 비활성화해서 디스크 공간을 절약할 수 있다.  

# null_value‌

색인 시 document(문서)에 필드가 없거나 필드의 값이 null 일 경우 보통은 필드가 생성되지 않는다. 하지만 만약 매핑시에 null_value를 세팅해두면 document 내의 해당 필드의 값이 null 이더라도 해당 기본값으로 데이터를 세팅한다.  

ex)

```bash
PUT financial_yearly 
{
  "mappings":{
    // ...
      "per": {
        "type": "double",
        "null_value": "0"
      },
    // ...
    }
  }
}
```

개인적인 사견으로는... null_value를 사용하기 전에 앞서서... 숫자형 데이터의 경우 필드를 하나 더 두어서 선택된 하나의 도큐먼트에 대해서 해당 필드가 null 인지 여부를 가리키는 필드를 매핑시 추가해놓고 사용하면 상관성분석과 같은 분석로직을 짤때 조금은 유용해지지 않을까 하는 생각이 든다.  

# properties

Object 또는 중첩 구조의 데이터를 작성할 때 사용되는 옵션이다. 필드의 타입을 매핑하는 역할을 한다. Object/중첩 필드는 properties라는 서브 필드가 있다.  

# ‌search_analyzer

특정 필드 하나에 대해서 특수한 분석기를 사용하려고 한다면 search_analyzer 파라미터를 설정하는 것으로 분석기를 별도 지정할 수 있다.  

# 마무으리...‌

우리는 MySQL, Oracle 을 배우면서 DDL 작성시에 필요한 컬럼 타입들을 외우고 다니지 않았다. 대신 설계시에 공식문서를 꼼꼼히 보고 자릿수가 어딧까지인지, 이 타입의 특별한 점은 무엇인지 등을 꼼꼼히 따져보고 세팅하는 편이었다. Elastic Search의 매핑 파라미터를 정리하는 과정은 DDL시의 컬럼 타입을 정리하는 것과 유사한 작업이라고 느꼈다. 그래서 이걸 계속 정리하는게 맞을까? 하는 생각이 자주 들었었다.  

하지만, Elastic Search 를 제대로 책을 보고 공부하면서 모두 정리해보면서 느낀 점은 Elastic Search는 기존의 데이터베이스와는 다른 점들이 많다는 점이었다. 그리고 추가로 느낀 점은 뭔가를 사소하게 꼼꼼히 공부하는 것과 넘겨짚어서 나중에 찾아보면 되지 하는 것과는 시간과 공간의 차이가 크다는 점이었다.  